<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" class="gr__cs_toronto_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="shortcut icon" href="https://www.cs.toronto.edu/~rjliao/imgs/myIcon.jpg">

<meta name="keywords" content="Yangyang Shu, Shu Yangyang, CS, privileged information, machine learning, UTS, USTC, University of Science and Technology of China, University of Technology, Sydney">
<meta name="description" content="Yangyang Shu&#39;s home page">
<link rel="stylesheet" href="./jemdoc.css" type="text/css">
<title>Yangyang Shu</title>

</head>
<body data-gr-c-s-loaded="true">

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Yangyang Shu &nbsp; <img src="./can_chinese.jpg" height="45px" style="margin-bottom:-10px"></h1><h1>
				</h1></div>

				<h3>D.Phil</h3>
			  <p>
					Australian Institute for Machine Learning<br>
					University of Adelaide <br>
					Adelaide, Australia <br>
          <br>
				Email: yangyang.shu at adelaide dot edu dot au
				
				<br>Github: <a href="https://github.com/GANPerf">https://github.com/GANPerf</a></p>
			</td><td>
				<img src="./me_pencil.jpg" border="0" width="200"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
  I am an Associate Lecturer in the School of Systems and Computing at the University of New South Wales (UNSW), Australia. Before that, I worked as a Research Fellow at the Australian Institute for Machine Learning (AIML), the University of Adelaide. 
  My advisor is Prof. <a href="https://lingqiao-adelaide.github.io/lingqiaoliu.github.io/">Lingqiao Liu</a>. I completed my Ph.D. in Data Science and Machine Intelligence Lab and the 
  Faculty of Engineering and Information Technology, University of Technology Sydney in 2021. My advisor is Prof. <a href="https://www.uts.edu.au/staff/guandong.xu">Guandong Xu.</a>
  I received M.S. degree in computer science from University of Science and Technology of China in 2018. 
  My advisor is Prof. <a href="http://staff.ustc.edu.cn/~sfwang/">Shangfei Wang.</a>
  I received a B.S. degree in computer science from Anhui University in 2015.

  
</p>

<p>My research interests lie in machine learning, computer vision, multimedia, privileged information and related applications in
artificial intelligence, including multi-task learning, fine-grained recognition, music emotion and photo aesthetics. </p>
	
</p>

<p>Recently, my major research topics are about:

</p>
	
<b>Rationale-guided Machine Learning</b>. 
The most machine learning system is based on the principle of Empirical Risk Minimization. 
Any features and classifiers that contribute to risk minimization will be acquired from the learning process. 
In this research theme, we consider prediction rationale – clues about why a certain decision is made in the learning process.
We are investigating how to represent rationale and how to put forward various regularizations on the rationale clues. 
This is expected to lead to more generalizable or more data-efficient machine learning systems.

</p>
	
<b>Large Language Models</b>.
I am deeply passionate about techniques that can enhance the training and deployment of large language models, with a particular focus on <b>music large language models</b>.
	My interests encompass a wide range of areas, including the development of improved training methodologies, advanced strategies for better generation control, 
	and the optimization of inference times. I am dedicated to exploring and implementing these techniques to push the boundaries of what large language models can achieve in the realm of music.</p>


<h2>Publications</h2>
<p>
<b>Pretrained Models and Language Models</b>.
</p>
	
<ul>
	<li>
    <a href="https://arxiv.org/abs/2407.04331">MuseBarControl: Enhancing Fine-Grained Control in Symbolic Music Generation through Pre-Training and Counterfactual Loss,<br></a>
    <b>Yangyang Shu</b>,  Haiming Xu, Ziqin Zhou, Anton van den Hengel, Lingqiao Liu*<br>
    <em>arXiv:2402.01157, 2024.</em> <a href="https://ganperf.github.io/musebarcontrol.github.io/musebarcontrol/">[Project]</a> <br>
  </li>

	<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Unlocking_the_Potential_of_Pre-trained_Vision_Transformers_for_Few-Shot_Semantic_CVPR_2024_paper.html">Unlocking the Potential of Pre-trained Vision Transformers for Few-Shot Semantic Segmentation through Relationship Descriptors,<br></a>
    Ziqin Zhou, Haiming Xu, <b>Yangyang Shu</b>, Lingqiao Liu*<br>
    <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024. </em> <a href="https://github.com/ZiqinZhou66/FewSegwithRD">[code]</a> <br>  
  </li>
</ul>

<b>Rationale-guided Machine Learning</b>.
</p>
	<ul>
	
   <li>
    <a href="https://arxiv.org/abs/2402.01157">Source-Free Unsupervised Domain Adaptation with Hypothesis Consolidation of Prediction Rationale,<br></a>
    <b>Yangyang Shu</b>,  Xiaofeng Cao, Qi Chen, Bowen Zhang, Ziqin Zhou, Anton van den Hengel, Lingqiao Liu*<br>
    <em>arXiv:2402.01157, 2024.</em> <a href="https://github.com/GANPerf/HCPR">[code]</a> <br>
  </li>
	
    <li>
    <a href="https://arxiv.org/abs/2303.01669">Learning Common Rationale to Improve Self-Supervised Representation for Fine-Grained Visual Recognition Problems,<br></a>
    <b>Yangyang Shu</b>, Anton van den Hengel, Lingqiao Liu*<br>
    <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.</em> <a href="https://github.com/GANPerf/LCR">[code]</a> <br>
  </li>

</ul>

<b>Low-supervision Learning</b>.
</p>

<ul>

  <li>
    <a href="https://arxiv.org/abs/2412.00134">PP-SSL : Priority-Perception Self-Supervised Learning for Fine-Grained Recognition,<br></a>
    ShuaiHeng Li, Qing Cai, Fan Zhang, Menghuan Zhang, <b>Yangyang Shu</b>, Zhi Liu, Huafeng Li, Lingqiao Liu<br>
    <em>arXiv:2412.00134, 2024.</em> <br>
  </li>
	
   <li>
    <a href="https://arxiv.org/abs/2208.00617">Improving Fine-Grained Visual Recognition in Low Data Regimes via Self-Boosting Attention Mechanism,<br></a>
    <b>Yangyang Shu</b>, Baosheng Yu, Haiming Xu, Lingqiao Liu*<br>
    <em>Proceedings of the European Conference on Computer Vision (<b>ECCV</b>), 2022.</em> <a href="https://github.com/GANPerf/SAM">[code]</a> <br>
  </li>

	<li>
    <a href="https://ieeexplore.ieee.org/abstract/document/9563269">Semi-supervised Adversarial Learning for Attribute-Aware Photo Aesthetic Assessment,<br></a>
    <b>Yangyang Shu</b>, Qian Li, Lingqiao Liu, Guandong Xu*<br>
    <em>IEEE Transactions on Multimedia</em> (<b>TMM</b>), 2021. <br>
  </li>
</ul>


<b>Privileged Machine Learning and Adversarial Learning</b>.
</p>
<ul>
	
    <li>
    <a href="https://www.sciencedirect.com/science/article/pii/S0031320322004022">Privileged Multi-Task Learning for Attribute-Aware Aesthetic Assessment,<br></a>
    <b>Yangyang Shu</b>, Qian Li, Lingqiao Liu, Guandong Xu*<br>
    <em><b>Pattern Recognition</b><em>, 2022. <br>
  </li>
	
    <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/9360466">V-SVR+: Support Vector Regression with Variational Privileged Information,<br></a>
    <b>Yangyang Shu</b>, Qian Li, Chang Xu, Shaowu Liu, Guandong Xu*<br>
    <em>IEEE Transactions on Multimedia</em> (<b>TMM</b>), 2021. <br>
  </li>
	
   <li>
    <a href="https://dl.acm.org/doi/abs/10.1145/3382494.3410677">Perf-AL: Performance Prediction for Configurable Software through Adversarial Learning,<br></a>
    <b>Yangyang Shu</b>, Yulei Sui, Hongyu Zhang, Guandong Xu*<br>
    <em>Empirical Software Engineering and Measurement</em> (<b>ESEM</b>), 2020. (21% accepted rate) <br>
  </li>
	  
  <li>
    <a href="https://www.sciencedirect.com/science/article/pii/S092523122030789X">Learning with Privileged Information for Photo Aesthetic Assessment,<br></a>
    <b>Yangyang Shu</b>, Qian Li, Shaowu Liu, Guandong Xu*<br>
    <em><b>Neurocomputing</b><em>, 2020. <br>
  </li>

</ul>
	    
<b>Affective Computing</b>.
</p>
<ul>
  <li>
    <a href="https://link.springer.com/chapter/10.1007/978-3-030-29908-8_10">Emotion Recognition from Music Enhanced by Domain Knowledge,<br></a>
    <b>Yangyang Shu</b>, Guandong Xu*<br>
    <em>The 16th Pacific Rim International Conference on Artificial Intelligence</em> (<b>PRICAI</b>), 2019. <br>
  </li>
  
  <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/8697096">Video Affective Content Analysis by Exploring Domain Knowledge,<br></a>
    Shangfei Wang*, Can Wang, Tanfang Chen, Yaxin Wang, <b>Yangyang Shu</b>, Qiang Ji<br>
    <em>IEEE Transactions on Affective Computing</em> (<b>TAC</b>), 2019. <br>
  </li>
  
  <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/7952681">Emotion recognition through integrating EEG and peripheral signals,<br></a>
    <b>Yangyang Shu</b>, Shangfei Wang*<br>
    <em>International Conference on Acoustics, Speech, and Signal Processing</em> (<b>ICASSP</b>), 2017. <br>
  </li>
  

    
</ul>

<h2>Employment</h2>
  <ul>
    <li>  Australia Grant-Funded Researcher: Waterbird Image Analysis in South Australia, 7/2021-7/2022. </li>
    <li>  A Project in Australian of Energy Market Electricity Price Forecast Using Meteorology Data, 9/2018-2/2019. </li>
    <li>  Learning in the Institute of Computer Technology, Chinese Academy of Sciences, 4/2017-5/2017. </li>
  </ul>


<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	
    <tbody><tr><td><i>National Scholarship of University of Science and Technology of China </i>, 2017 (14/150)</td></tr>

    <tr><td><i> The sixth national college student mathematics competition</i>, the Second Prize, 2014.</td></tr>
    <tr><td><i> Outstanding Graduate of University of Science and Technology of China</i>, 2018 </td></tr>
    <tr><td><i> Outstanding Graduate of Anhui Province</i>, 2015 </td></tr>

		

	</tbody>
</table>

<h2>Miscellany</h2>
<p>Hobbies: <a href="https://www.bilibili.com/video/BV1Th411Z7YG">Erhu</a>, Piano, <a href="https://www.youtube.com/watch?app=desktop&v=zbnMF_v8twI&feature=youtu.be">Music</a>.<br>

<p>Last Updated by Yangyang Shu: Aug. 1 2022</p>
<div id="footer">
	<div id="footer-text"></div>
</div>
</div>
